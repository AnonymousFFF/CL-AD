{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077f7812",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#正常数据&PGD数据\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import art\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# 定义数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 加载CIFAR-10数据集\n",
    "trainset = torchvision.datasets.CIFAR10(root='./cifar10', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./cifar10', train=False, download=True, transform=transform)\n",
    "\n",
    "# 合并训练集和测试集\n",
    "combined_data = trainset.data\n",
    "combined_labels = trainset.targets\n",
    "combined_data = np.concatenate((combined_data, testset.data), axis=0)\n",
    "combined_labels = np.concatenate((combined_labels, testset.targets), axis=0)\n",
    "\n",
    "# 获取类别名称\n",
    "class_names = trainset.classes\n",
    "\n",
    "# 创建一个字典来存储每个类别的DataFrame\n",
    "dataframes = {}\n",
    "\n",
    "# 按标签分组数据\n",
    "for label in range(len(class_names)):\n",
    "    # 获取当前标签的索引\n",
    "    indices = np.where(combined_labels == label)[0]\n",
    "    \n",
    "    # 提取对应的数据和标签\n",
    "    label_data = combined_data[indices]\n",
    "    label_labels = combined_labels[indices]\n",
    "    \n",
    "    # 创建DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'image': [img for img in label_data],\n",
    "        'label': label_labels\n",
    "    })\n",
    "    \n",
    "    # 用类别名称命名DataFrame\n",
    "    dataframes[class_names[label]] = df\n",
    "    \n",
    "# 从合并后的CSV文件中读取数据并恢复attacked_dataframes\n",
    "def load_attacked_dataframes_from_csv(filename='merged_pgd.csv'):\n",
    "    # 读取CSV文件\n",
    "    all_data = pd.read_csv(filename)\n",
    "    \n",
    "    # 将图像数据从字符串格式转换回NumPy数组\n",
    "    all_data['image'] = all_data['image'].apply(lambda x: np.frombuffer(eval(x), dtype=np.uint8).reshape(32, 32, 3))\n",
    "    \n",
    "    # 按类别名称分组并创建字典\n",
    "    attacked_dataframes = {}\n",
    "    for class_name in all_data['class_name'].unique():\n",
    "        class_data = all_data[all_data['class_name'] == class_name]\n",
    "        df = class_data[['image', 'label']].reset_index(drop=True)\n",
    "        attacked_dataframes[class_name] = df\n",
    "    \n",
    "    return attacked_dataframes\n",
    "pgds = load_attacked_dataframes_from_csv(\"./adv/deepfools.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc23eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 定义与保存时一致的模型结构\n",
    "\"\"\"class ModifiedResNet18(torch.nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ModifiedResNet18, self).__init__()\n",
    "        self.resnet18 = models.resnet18(pretrained=False)  # 不使用预训练权重，因为我们加载的是已经训练好的模型\n",
    "        self.resnet18.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.resnet18.maxpool = torch.nn.Identity()  # 移除最大池化层\n",
    "        \n",
    "        # 获取ResNet18的特征提取部分\n",
    "        self.features = torch.nn.Sequential(*list(self.resnet18.children())[:-1])\n",
    "        \n",
    "        # 添加MLP和全连接层\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.Linear(256, 128),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(0.5)\n",
    "        )\n",
    "        self.fc = torch.nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.mlp(x)\n",
    "        x = self.fc(x)\n",
    "        return x\"\"\"\n",
    "class ModifiedResNet18(torch.nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ModifiedResNet18, self).__init__()\n",
    "        self.resnet18 = models.resnet18(pretrained=False)  # 不使用预训练权重，因为我们加载的是已经训练好的模型\n",
    "        self.resnet18.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.resnet18.maxpool = torch.nn.Identity()  # 移除最大池化层\n",
    "        \n",
    "        # 获取ResNet18的特征提取部分\n",
    "        self.features = torch.nn.Sequential(*list(self.resnet18.children())[:-1])\n",
    "        \n",
    "        # 添加MLP和全连接层\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.Linear(256, 128),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(0.5)\n",
    "        )\n",
    "        self.fc = torch.nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.mlp(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def get_all_activations(self, x, hook):\n",
    "        # 前向传播\n",
    "        with torch.no_grad():\n",
    "            self(x)\n",
    "        \n",
    "        # 处理激活值\n",
    "        features = []\n",
    "        for name in hook.activations:\n",
    "            layer_act = hook.activations[name].squeeze()\n",
    "            if len(layer_act.shape) == 3:  # 卷积层特征\n",
    "                features.append(torch.mean(layer_act, dim=(1, 2)))  # 全局平均池化\n",
    "            else:  # 全连接层特征\n",
    "                features.append(layer_act.flatten())\n",
    "        return torch.cat(features, dim=1)\n",
    "\n",
    "\n",
    "# 初始化模型\n",
    "model = ModifiedResNet18()\n",
    "\n",
    "# 加载保存的模型权重\n",
    "model_path = 'best_model.pth'  # 替换为你的模型文件路径\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4c4da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#钩子函数\n",
    "class ActivationHook:\n",
    "    def __init__(self):\n",
    "        self.activations = {}\n",
    "        \n",
    "    def get_hook(self, name):\n",
    "        def hook(module, input, output):\n",
    "            self.activations[name] = output.detach()\n",
    "        return hook\n",
    "\n",
    "# 初始化钩子管理器\n",
    "hook = ActivationHook()\n",
    "\n",
    "# 为模型的所有卷积层和全连接层注册钩子\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, (torch.nn.Conv2d, torch.nn.Linear)):\n",
    "        module.register_forward_hook(hook.get_hook(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5f897a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征提取器\n",
    "def extract_features(image, transform):\n",
    "    # 应用数据增强\n",
    "    img_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # 前向传播获取激活\n",
    "    with torch.no_grad():\n",
    "        model(img_tensor)\n",
    "    \n",
    "    # 处理各层激活\n",
    "    features = []\n",
    "    for name in hook.activations:\n",
    "        layer_act = hook.activations[name].squeeze()\n",
    "        if len(layer_act.shape) == 3:  # 卷积层特征\n",
    "            features.append(torch.mean(layer_act, dim=(1, 2)))  # 全局平均池化\n",
    "        else:  # 全连接层特征\n",
    "            features.append(layer_act.flatten())\n",
    "    return torch.cat(features).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f2a9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据增强手段\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 定义多种数据增强方法\n",
    "advanced_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomApply([\n",
    "        transforms.ColorJitter(0.8, 0.8, 0.8, 0.2)\n",
    "    ], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomResizedCrop(32, scale=(0.6, 1.0)),\n",
    "    transforms.GaussianBlur(3),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c07511",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "# 修改后的build_dataset函数，生成视图对\n",
    "def build_supervised_pairs(data_dict, label_type, num_samples=6000):\n",
    "    pairs = []\n",
    "    \n",
    "    for class_name in tqdm(data_dict.keys()):\n",
    "        df = data_dict[class_name]\n",
    "        # 创建索引数组\n",
    "        available_indices = np.arange(len(df))\n",
    "        # 随机选择索引（允许重复）\n",
    "        selected_indices = np.random.choice(available_indices, num_samples, replace=True)\n",
    "        \n",
    "        for idx in selected_indices:\n",
    "            sample = df.iloc[idx]\n",
    "            img = sample['image']\n",
    "            \n",
    "            # 为每个样本生成4个视图\n",
    "            views = [extract_features(img, advanced_transform) for _ in range(4)]\n",
    "            \n",
    "            # 添加同样本正对\n",
    "            for i in range(4):\n",
    "                for j in range(i+1, 4):\n",
    "                    pairs.append((views[i], views[j], label_type))\n",
    "            \n",
    "            # 添加跨样本正对（从同一类中随机选2个其他样本）\n",
    "            other_indices = np.random.choice(available_indices, 2, replace=True)\n",
    "            for other_idx in other_indices:\n",
    "                other_sample = df.iloc[other_idx]\n",
    "                other_view = extract_features(other_sample['image'], advanced_transform)\n",
    "                pairs.extend([\n",
    "                    (views[0], other_view, label_type),\n",
    "                    (views[1], other_view, label_type)\n",
    "                ])\n",
    "    \n",
    "    return pairs\n",
    "    \n",
    "# 构建配对数据集\n",
    "normal_pairs = build_supervised_pairs(dataframes, 0)\n",
    "adv_pairs = build_supervised_pairs(pgds, 1)\n",
    "all_pairs = normal_pairs + adv_pairs\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "def save_pairs(adv_pairs, normal_pairs, folder_name):\n",
    "    # 创建文件夹\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "    \n",
    "    # 保存adv_pairs\n",
    "    with open(os.path.join(folder_name, 'adv_pairs.pkl'), 'wb') as f:\n",
    "        pickle.dump(adv_pairs, f)\n",
    "    \n",
    "    # 保存normal_pairs\n",
    "    with open(os.path.join(folder_name, 'normal_pairs.pkl'), 'wb') as f:\n",
    "        pickle.dump(normal_pairs, f)\n",
    "    \n",
    "\n",
    "    print(f\"Data saved to {folder_name} successfully.\")\n",
    "\n",
    "\n",
    "save_pairs(adv_pairs, normal_pairs, 'deepfoolpairs')\n",
    "\n",
    "\"\"\"\n",
    "def load_pairs(folder_name):\n",
    "    # 加载adv_pairs\n",
    "    with open(os.path.join(folder_name, 'adv_pairs.pkl'), 'rb') as f:\n",
    "        adv_pairs = pickle.load(f)\n",
    "    \n",
    "    # 加载normal_pairs\n",
    "    with open(os.path.join(folder_name, 'normal_pairs.pkl'), 'rb') as f:\n",
    "        normal_pairs = pickle.load(f)\n",
    "    \n",
    "    # 加载all_pairs\n",
    "    all_pairs = normal_pairs + adv_pairs\n",
    "    print(f\"Data loaded from {folder_name} successfully.\")\n",
    "    return adv_pairs, normal_pairs, all_pairs\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68d3080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集、验证集、测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_pairs, test_pairs = train_test_split(all_pairs, test_size=0.3, random_state=42)\n",
    "\n",
    "# 创建Dataset类\n",
    "class ContrastivePairDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, pairs):\n",
    "        self.pairs = pairs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        view1, view2, label = self.pairs[idx]\n",
    "        return (\n",
    "            torch.FloatTensor(view1),\n",
    "            torch.FloatTensor(view2),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "# 创建DataLoader\n",
    "train_dataset = ContrastivePairDataset(train_pairs)\n",
    "\n",
    "test_dataset = ContrastivePairDataset(test_pairs)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, drop_last=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e235b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import csv\n",
    "\n",
    "\n",
    "# 定义对比学习模型\n",
    "class ContrastiveDetector(nn.Module):\n",
    "    def __init__(self, input_dim=5194):\n",
    "        super(ContrastiveDetector, self).__init__()\n",
    "        # 共享权重的双塔编码器\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 2048),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # 对比头（相似度度量）\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128)\n",
    "        )\n",
    "        \n",
    "        # 分类头\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512*2, 256),  # 拼接特征\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # 编码器处理\n",
    "        emb1 = self.encoder(x1)\n",
    "        emb2 = self.encoder(x2)\n",
    "        \n",
    "        # 对比学习分支\n",
    "        proj1 = self.projection(emb1)\n",
    "        proj2 = self.projection(emb2)\n",
    "        \n",
    "        # 分类分支\n",
    "        combined = torch.cat([emb1, emb2], dim=1)\n",
    "        logits = self.classifier(combined)\n",
    "        \n",
    "        return proj1, proj2, logits.squeeze()\n",
    "\n",
    "# 复合损失函数：对比损失 + 分类损失\n",
    "class HybridLoss(nn.Module):\n",
    "    def __init__(self, temp=0.1, alpha=0.7):\n",
    "        super().__init__()\n",
    "        self.temp = temp\n",
    "        self.alpha = alpha\n",
    "        self.ce_loss = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "    def contrastive_loss(self, proj1, proj2):\n",
    "        # 计算标准化嵌入\n",
    "        proj1 = nn.functional.normalize(proj1, dim=1)\n",
    "        proj2 = nn.functional.normalize(proj2, dim=1)\n",
    "        \n",
    "        # 计算相似度矩阵\n",
    "        logits = (proj1 @ proj2.T) / self.temp\n",
    "        labels = torch.arange(logits.size(0)).to(logits.device)\n",
    "        \n",
    "        loss1 = nn.functional.cross_entropy(logits, labels)\n",
    "        loss2 = nn.functional.cross_entropy(logits.T, labels)\n",
    "        return (loss1 + loss2) / 2\n",
    "    \n",
    "    # 修改HybridLoss的forward方法\n",
    "    def forward(self, proj1, proj2, logits, targets):\n",
    "        cont_loss = self.contrastive_loss(proj1, proj2)\n",
    "        cls_loss = self.ce_loss(logits, targets.float().squeeze())  # 添加squeeze()\n",
    "        return self.alpha*cont_loss + (1-self.alpha)*cls_loss\n",
    "\n",
    "# 修改后的训练函数\n",
    "# 修改训练函数（添加准确率记录）\n",
    "def train_model(model, train_loader, test_loader, epochs=50, lr=1e-4):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    history = {\n",
    "        'epoch': [],\n",
    "        'train_loss': [], 'train_acc': [], 'train_auc': [],\n",
    "        'test_loss': [], 'test_acc': [], 'test_auc': []\n",
    "    }\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    criterion = HybridLoss(temp=0.2, alpha=0.5)\n",
    "    \n",
    "    best_auc = 0\n",
    "    for epoch in range(epochs):\n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_preds, train_probs, train_targets = [], [], []\n",
    "        \n",
    "        for x1, x2, labels in train_loader:\n",
    "            x1, x2, labels = x1.to(device), x2.to(device), labels.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            proj1, proj2, logits = model(x1, x2)\n",
    "            \n",
    "            loss = criterion(proj1, proj2, logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            probs = torch.sigmoid(logits)\n",
    "            train_probs.append(probs.detach().cpu())\n",
    "            train_preds.append((probs > 0.5).long().cpu())\n",
    "            train_targets.append(labels.cpu())\n",
    "        \n",
    "        # 计算训练指标\n",
    "        train_probs = torch.cat(train_probs)\n",
    "        train_preds = torch.cat(train_preds)\n",
    "        train_targets = torch.cat(train_targets)\n",
    "        train_acc = accuracy_score(train_targets, train_preds)\n",
    "        train_auc = roc_auc_score(train_targets, train_probs)\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        # 测试集评估\n",
    "        test_loss, test_acc, test_auc = evaluate_during_training(model, test_loader, criterion, device)\n",
    "        \n",
    "        # 记录历史\n",
    "        history['epoch'].append(epoch+1)\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['train_auc'].append(train_auc)\n",
    "        history['test_loss'].append(test_loss)\n",
    "        history['test_acc'].append(test_acc)\n",
    "        history['test_auc'].append(test_auc)\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if test_auc > best_auc:\n",
    "            best_auc = test_auc\n",
    "            torch.save(model.state_dict(), \"CL_deepbest_model.pth\")\n",
    "        \n",
    "        # 打印进度\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        print(f\"Train Loss: {avg_train_loss:.4f} | Acc: {train_acc:.4f} | AUC: {train_auc:.4f}\")\n",
    "        print(f\"Test  Loss: {test_loss:.4f} | Acc: {test_acc:.4f} | AUC: {test_auc:.4f}\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "        \n",
    "        # 保存记录到CSV\n",
    "        with open('deepftraining_log.csv', 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                epoch + 1,\n",
    "                avg_train_loss,\n",
    "                train_acc,\n",
    "                train_auc,\n",
    "                test_loss,\n",
    "                test_acc,\n",
    "                test_auc\n",
    "            ])\n",
    "\n",
    "    \n",
    "    return history\n",
    "\n",
    "# 修改评估函数（返回准确率和AUC）\n",
    "def evaluate_during_training(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds, all_probs, all_targets = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x1, x2, labels in loader:\n",
    "            x1, x2, labels = x1.to(device), x2.to(device), labels.float().to(device)\n",
    "            \n",
    "            _, _, logits = model(x1, x2)\n",
    "            loss = criterion.ce_loss(logits, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            probs = torch.sigmoid(logits)\n",
    "            all_probs.append(probs.cpu())\n",
    "            all_preds.append((probs > 0.5).long().cpu())\n",
    "            all_targets.append(labels.cpu())\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    all_probs = torch.cat(all_probs)\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_targets = torch.cat(all_targets)\n",
    "    \n",
    "    acc = accuracy_score(all_targets, all_preds)\n",
    "    auc = roc_auc_score(all_targets, all_probs)\n",
    "    return avg_loss, acc, auc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 初始化并训练模型\n",
    "model = ContrastiveDetector()\n",
    "history = train_model(model, train_loader, test_loader, epochs=20, lr=2e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ae5c12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
