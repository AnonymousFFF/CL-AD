{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "096b63bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch: 1, Train Loss: 1.2329, Train Acc: 56.55%\n",
      "Test Loss: 0.7524, Test Acc: 75.72%\n",
      "Saved best model with accuracy 75.72%\n",
      "Epoch: 2, Train Loss: 0.5925, Train Acc: 81.64%\n",
      "Test Loss: 0.5636, Test Acc: 82.76%\n",
      "Saved best model with accuracy 82.76%\n",
      "Epoch: 3, Train Loss: 0.4694, Train Acc: 85.79%\n",
      "Test Loss: 0.4999, Test Acc: 83.87%\n",
      "Saved best model with accuracy 83.87%\n",
      "Epoch: 4, Train Loss: 0.3988, Train Acc: 87.71%\n",
      "Test Loss: 0.6229, Test Acc: 81.06%\n",
      "Epoch: 5, Train Loss: 0.3608, Train Acc: 88.89%\n",
      "Test Loss: 0.5610, Test Acc: 81.55%\n",
      "Epoch: 6, Train Loss: 0.3252, Train Acc: 89.91%\n",
      "Test Loss: 0.5619, Test Acc: 82.33%\n",
      "Epoch: 7, Train Loss: 0.3007, Train Acc: 90.66%\n",
      "Test Loss: 0.5202, Test Acc: 84.52%\n",
      "Saved best model with accuracy 84.52%\n",
      "Epoch: 8, Train Loss: 0.2936, Train Acc: 90.96%\n",
      "Test Loss: 0.5120, Test Acc: 84.34%\n",
      "Epoch: 9, Train Loss: 0.2696, Train Acc: 91.58%\n",
      "Test Loss: 0.3844, Test Acc: 87.97%\n",
      "Saved best model with accuracy 87.97%\n",
      "Epoch: 10, Train Loss: 0.2656, Train Acc: 91.71%\n",
      "Test Loss: 0.4090, Test Acc: 87.17%\n",
      "Epoch: 11, Train Loss: 0.2560, Train Acc: 92.02%\n",
      "Test Loss: 0.3727, Test Acc: 88.13%\n",
      "Saved best model with accuracy 88.13%\n",
      "Epoch: 12, Train Loss: 0.2389, Train Acc: 92.52%\n",
      "Test Loss: 0.4802, Test Acc: 86.44%\n",
      "Epoch: 13, Train Loss: 0.2439, Train Acc: 92.31%\n",
      "Test Loss: 0.4447, Test Acc: 87.11%\n",
      "Epoch: 14, Train Loss: 0.2342, Train Acc: 92.64%\n",
      "Test Loss: 0.3459, Test Acc: 89.28%\n",
      "Saved best model with accuracy 89.28%\n",
      "Epoch: 15, Train Loss: 0.2262, Train Acc: 93.06%\n",
      "Test Loss: 0.4960, Test Acc: 85.60%\n",
      "Epoch: 16, Train Loss: 0.2126, Train Acc: 93.45%\n",
      "Test Loss: 0.4431, Test Acc: 87.30%\n",
      "Epoch: 17, Train Loss: 0.2065, Train Acc: 93.55%\n",
      "Test Loss: 0.4008, Test Acc: 88.25%\n",
      "Epoch: 18, Train Loss: 0.2121, Train Acc: 93.36%\n",
      "Test Loss: 0.4499, Test Acc: 86.52%\n",
      "Epoch: 19, Train Loss: 0.2089, Train Acc: 93.52%\n",
      "Test Loss: 0.4964, Test Acc: 86.07%\n",
      "Epoch: 20, Train Loss: 0.2069, Train Acc: 93.49%\n",
      "Test Loss: 0.3578, Test Acc: 88.88%\n",
      "Epoch: 21, Train Loss: 0.1999, Train Acc: 93.74%\n",
      "Test Loss: 0.3464, Test Acc: 89.64%\n",
      "Saved best model with accuracy 89.64%\n",
      "Epoch: 22, Train Loss: 0.1993, Train Acc: 93.70%\n",
      "Test Loss: 0.5167, Test Acc: 85.34%\n",
      "Epoch: 23, Train Loss: 0.1973, Train Acc: 93.86%\n",
      "Test Loss: 0.3878, Test Acc: 88.83%\n",
      "Epoch: 24, Train Loss: 0.1953, Train Acc: 93.92%\n",
      "Test Loss: 0.4829, Test Acc: 86.71%\n",
      "Epoch: 25, Train Loss: 0.1937, Train Acc: 94.00%\n",
      "Test Loss: 0.3111, Test Acc: 90.53%\n",
      "Saved best model with accuracy 90.53%\n",
      "Epoch: 26, Train Loss: 0.1872, Train Acc: 94.18%\n",
      "Test Loss: 0.4103, Test Acc: 88.43%\n",
      "Epoch: 27, Train Loss: 0.1809, Train Acc: 94.43%\n",
      "Test Loss: 0.3563, Test Acc: 89.07%\n",
      "Epoch: 28, Train Loss: 0.1866, Train Acc: 94.27%\n",
      "Test Loss: 0.4893, Test Acc: 86.89%\n",
      "Epoch: 29, Train Loss: 0.1869, Train Acc: 94.13%\n",
      "Test Loss: 0.5247, Test Acc: 85.13%\n",
      "Epoch: 30, Train Loss: 0.1879, Train Acc: 94.09%\n",
      "Test Loss: 0.3858, Test Acc: 87.82%\n",
      "Epoch: 31, Train Loss: 0.1832, Train Acc: 94.23%\n",
      "Test Loss: 0.3359, Test Acc: 89.63%\n",
      "Epoch: 32, Train Loss: 0.1793, Train Acc: 94.41%\n",
      "Test Loss: 0.3908, Test Acc: 88.65%\n",
      "Epoch: 33, Train Loss: 0.1748, Train Acc: 94.55%\n",
      "Test Loss: 0.3470, Test Acc: 90.03%\n",
      "Epoch: 34, Train Loss: 0.1775, Train Acc: 94.47%\n",
      "Test Loss: 0.4680, Test Acc: 86.20%\n",
      "Epoch: 35, Train Loss: 0.1713, Train Acc: 94.55%\n",
      "Test Loss: 0.6424, Test Acc: 83.24%\n",
      "Epoch: 36, Train Loss: 0.1822, Train Acc: 94.31%\n",
      "Test Loss: 0.4699, Test Acc: 87.19%\n",
      "Epoch: 37, Train Loss: 0.1746, Train Acc: 94.64%\n",
      "Test Loss: 0.4107, Test Acc: 87.90%\n",
      "Epoch: 38, Train Loss: 0.1727, Train Acc: 94.60%\n",
      "Test Loss: 0.3173, Test Acc: 90.59%\n",
      "Saved best model with accuracy 90.59%\n",
      "Epoch: 39, Train Loss: 0.1645, Train Acc: 94.91%\n",
      "Test Loss: 0.4625, Test Acc: 86.94%\n",
      "Epoch: 40, Train Loss: 0.1690, Train Acc: 94.77%\n",
      "Test Loss: 0.4494, Test Acc: 87.44%\n",
      "Epoch: 41, Train Loss: 0.1728, Train Acc: 94.52%\n",
      "Test Loss: 0.4617, Test Acc: 86.74%\n",
      "Epoch: 42, Train Loss: 0.1625, Train Acc: 94.90%\n",
      "Test Loss: 0.4580, Test Acc: 86.96%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 124\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinished Training\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# 调用训练函数\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 86\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[0;32m     84\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     85\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 86\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     88\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 定义数据预处理\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# 加载CIFAR10数据集\n",
    "trainset = torchvision.datasets.CIFAR10(root='./cifar10', train=True, download=True, transform=transform_train)\n",
    "trainloader = DataLoader(trainset, batch_size=512, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./cifar10', train=False, download=True, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=200, shuffle=False, num_workers=2)\n",
    "\n",
    "# 定义修改后的ResNet18模型\n",
    "class ModifiedResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ModifiedResNet18, self).__init__()\n",
    "        # 加载预训练的ResNet18\n",
    "        self.resnet18 = torchvision.models.resnet18(pretrained=True)\n",
    "        # 修改第一层卷积以适应CIFAR10的32x32图像\n",
    "        self.resnet18.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.resnet18.maxpool = nn.Identity()  # 移除最大池化层\n",
    "        \n",
    "        # 获取ResNet18的特征提取部分\n",
    "        self.features = nn.Sequential(*list(self.resnet18.children())[:-1])\n",
    "        \n",
    "        # 添加MLP和全连接层\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.mlp(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 初始化模型\n",
    "model = ModifiedResNet18().to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100, 150], gamma=0.1)\n",
    "\n",
    "# 训练模型\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=200):\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        train_loss = running_loss / len(trainloader)\n",
    "        train_acc = 100. * correct / total\n",
    "        print(f'Epoch: {epoch+1}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "\n",
    "        # 测试阶段\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in testloader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "        test_loss /= len(testloader)\n",
    "        test_acc = 100. * correct / total\n",
    "        print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%')\n",
    "\n",
    "        # 保存最佳模型\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(f'Saved best model with accuracy {best_acc:.2f}%')\n",
    "\n",
    "        # 调整学习率\n",
    "        scheduler.step()\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "# 调用训练函数\n",
    "train_model(model, criterion, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138a6efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, criterion, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44b668e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
