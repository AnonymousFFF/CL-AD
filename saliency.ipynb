{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e97aa2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt_to_dict(file_path):\n",
    "    result_dict = {}\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                # 去掉行首尾的空白字符，并按列分隔\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 2:\n",
    "                    print(f\"警告：跳过格式不正确的行 - {line.strip()}\")\n",
    "                    continue\n",
    "                index_name, value = parts\n",
    "                # 将第一列作为键，第二列作为值存入字典\n",
    "                result_dict[index_name] = value\n",
    "        return result_dict\n",
    "    except FileNotFoundError:\n",
    "        print(f\"错误：文件 {file_path} 未找到！\")\n",
    "        return {}\n",
    "    except Exception as e:\n",
    "        print(f\"发生错误：{e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc94c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"D:\\python\\val.txt\"\n",
    "data_dict = read_txt_to_dict(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ebddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "\n",
    "# 定义数据集类\n",
    "class ImageNetSubsetDataset(Dataset):\n",
    "    def __init__(self, root_dir, labellist,transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = os.listdir(root_dir)\n",
    "        self.labellist=labellist\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        for idx, cls in enumerate(self.classes):\n",
    "            cls_dir = os.path.join(root_dir, cls)\n",
    "            self.image_paths.append(cls_dir)\n",
    "            name = cls.split(\".\")[0]\n",
    "            name = name+\".png\"\n",
    "            self.labels.append(labellist[name])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# 定义预处理变换\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 加载本地ImageNet数据\n",
    "root_dir = r\"D:\\python\\imagenet\"  # 替换为你的本地ImageNet数据路径\n",
    "dataset = ImageNetSubsetDataset(root_dir,data_dict, transform=data_transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "# 加载预训练的ResNet18模型\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# 提取特征图\n",
    "def extract_features(model, dataloader):\n",
    "    features = []\n",
    "    with torch.no_grad():\n",
    "        for images, _ in dataloader:\n",
    "            outputs = model.conv1(images)\n",
    "            outputs = model.bn1(outputs)\n",
    "            outputs = model.relu(outputs)\n",
    "            outputs = model.maxpool(outputs)\n",
    "            outputs = model.layer1(outputs)\n",
    "            outputs = model.layer2(outputs)\n",
    "            outputs = model.layer3(outputs)\n",
    "            outputs = model.layer4(outputs)\n",
    "            features.append(outputs.cpu().numpy())\n",
    "    return np.concatenate(features, axis=0)\n",
    "\n",
    "cnn_feature_maps = extract_features(model, dataloader)\n",
    "\n",
    "# 定义解释图类\n",
    "class ExplanatoryGraph:\n",
    "    def __init__(self, num_layers, num_filters_per_layer, num_patterns_per_filter):\n",
    "        self.num_layers = num_layers\n",
    "        self.num_filters_per_layer = num_filters_per_layer\n",
    "        self.num_patterns_per_filter = num_patterns_per_filter\n",
    "        self.graph = {}\n",
    "\n",
    "    def build_graph(self, cnn_feature_maps):\n",
    "        for layer_idx in range(self.num_layers):\n",
    "            layer_feature_maps = cnn_feature_maps[layer_idx]\n",
    "            self.graph[layer_idx] = {}\n",
    "            for filter_idx in range(self.num_filters_per_layer[layer_idx]):\n",
    "                filter_feature_map = layer_feature_maps[filter_idx]\n",
    "                # 使用聚类方法解缠部件模式\n",
    "                patterns = self._disentangle_patterns(filter_feature_map)\n",
    "                self.graph[layer_idx][filter_idx] = patterns\n",
    "\n",
    "    def _disentangle_patterns(self, feature_map):\n",
    "        # 使用高斯混合模型进行聚类\n",
    "        gmm = GaussianMixture(n_components=self.num_patterns_per_filter)\n",
    "        gmm.fit(feature_map.reshape(-1, 1))\n",
    "        return gmm.means_.flatten()\n",
    "\n",
    "    def train(self, cnn_feature_maps, num_iterations=100):\n",
    "        for iteration in range(num_iterations):\n",
    "            for layer_idx in range(self.num_layers):\n",
    "                for filter_idx in range(self.num_filters_per_layer[layer_idx]):\n",
    "                    patterns = self.graph[layer_idx][filter_idx]\n",
    "                    # 更新模式参数\n",
    "                    self._update_patterns(patterns, cnn_feature_maps[layer_idx][filter_idx])\n",
    "\n",
    "    def _update_patterns(self, patterns, feature_map):\n",
    "        # 使用EM算法更新模式参数\n",
    "        # 这里只是一个简化的示例，实际实现需要更复杂的细节\n",
    "        kmeans = KMeans(n_clusters=self.num_patterns_per_filter)\n",
    "        kmeans.fit(feature_map.reshape(-1, 1))\n",
    "        patterns[:] = kmeans.cluster_centers_.flatten()\n",
    "\n",
    "# 构建解释图\n",
    "num_layers = 4\n",
    "num_filters_per_layer = [64, 128, 256, 512]  # 根据ResNet18的结构设置\n",
    "num_patterns_per_filter = 5  # 每个滤波器解缠出5个模式\n",
    "explanatory_graph = ExplanatoryGraph(num_layers, num_filters_per_layer, num_patterns_per_filter)\n",
    "explanatory_graph.build_graph(cnn_feature_maps)\n",
    "\n",
    "# 训练解释图\n",
    "explanatory_graph.train(cnn_feature_maps)\n",
    "\n",
    "# 输出结果\n",
    "print(\"Explanatory Graph:\")\n",
    "for layer_idx in range(num_layers):\n",
    "    for filter_idx in range(num_filters_per_layer[layer_idx]):\n",
    "        patterns = explanatory_graph.graph[layer_idx][filter_idx]\n",
    "        print(f\"Layer {layer_idx}, Filter {filter_idx}: {patterns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1b1200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
