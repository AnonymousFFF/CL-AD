{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cae5e95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90db99e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93b405b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './adv/fgsms.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 68\u001b[0m\n\u001b[0;32m     65\u001b[0m         attacked_dataframes[class_name] \u001b[38;5;241m=\u001b[39m df\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attacked_dataframes\n\u001b[1;32m---> 68\u001b[0m pgds \u001b[38;5;241m=\u001b[39m \u001b[43mload_attacked_dataframes_from_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./adv/fgsms.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 55\u001b[0m, in \u001b[0;36mload_attacked_dataframes_from_csv\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_attacked_dataframes_from_csv\u001b[39m(filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmerged_pgd.csv\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m# 读取CSV文件\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m     all_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;66;03m# 将图像数据从字符串格式转换回NumPy数组\u001b[39;00m\n\u001b[0;32m     58\u001b[0m     all_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m all_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mfrombuffer(\u001b[38;5;28meval\u001b[39m(x), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\call\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\call\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\call\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\call\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\call\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './adv/fgsms.csv'"
     ]
    }
   ],
   "source": [
    "#正常数据&PGD数据\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import art\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 定义数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 加载CIFAR-10数据集\n",
    "trainset = torchvision.datasets.CIFAR10(root='./cifar10', train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./cifar10', train=False, download=True, transform=transform)\n",
    "\n",
    "# 合并训练集和测试集\n",
    "combined_data = trainset.data\n",
    "combined_labels = trainset.targets\n",
    "combined_data = np.concatenate((combined_data, testset.data), axis=0)\n",
    "combined_labels = np.concatenate((combined_labels, testset.targets), axis=0)\n",
    "\n",
    "# 获取类别名称\n",
    "class_names = trainset.classes\n",
    "\n",
    "# 创建一个字典来存储每个类别的DataFrame\n",
    "dataframes = {}\n",
    "\n",
    "# 按标签分组数据\n",
    "for label in range(len(class_names)):\n",
    "    # 获取当前标签的索引\n",
    "    indices = np.where(combined_labels == label)[0]\n",
    "    \n",
    "    # 提取对应的数据和标签\n",
    "    label_data = combined_data[indices]\n",
    "    label_labels = combined_labels[indices]\n",
    "    \n",
    "    # 创建DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'image': [img for img in label_data],\n",
    "        'label': label_labels\n",
    "    })\n",
    "    \n",
    "    # 用类别名称命名DataFrame\n",
    "    dataframes[class_names[label]] = df\n",
    "    \n",
    "# 从合并后的CSV文件中读取数据并恢复attacked_dataframes\n",
    "def load_attacked_dataframes_from_csv(filename='merged_pgd.csv'):\n",
    "    # 读取CSV文件\n",
    "    all_data = pd.read_csv(filename)\n",
    "    \n",
    "    # 将图像数据从字符串格式转换回NumPy数组\n",
    "    all_data['image'] = all_data['image'].apply(lambda x: np.frombuffer(eval(x), dtype=np.uint8).reshape(32, 32, 3))\n",
    "    \n",
    "    # 按类别名称分组并创建字典\n",
    "    attacked_dataframes = {}\n",
    "    for class_name in all_data['class_name'].unique():\n",
    "        class_data = all_data[all_data['class_name'] == class_name]\n",
    "        df = class_data[['image', 'label']].reset_index(drop=True)\n",
    "        attacked_dataframes[class_name] = df\n",
    "    \n",
    "    return attacked_dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbb9ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgds = load_attacked_dataframes_from_csv(\"./adv/fgsm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3195e027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\call\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\anaconda\\envs\\call\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModifiedResNet18(\n",
       "  (resnet18): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): Identity()\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       "  )\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Identity()\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  )\n",
       "  (mlp): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#模型\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 定义与保存时一致的模型结构\n",
    "class ModifiedResNet18(torch.nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ModifiedResNet18, self).__init__()\n",
    "        self.resnet18 = models.resnet18(pretrained=False)  # 不使用预训练权重，因为我们加载的是已经训练好的模型\n",
    "        self.resnet18.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.resnet18.maxpool = torch.nn.Identity()  # 移除最大池化层\n",
    "        \n",
    "        # 获取ResNet18的特征提取部分\n",
    "        self.features = torch.nn.Sequential(*list(self.resnet18.children())[:-1])\n",
    "        \n",
    "        # 添加MLP和全连接层\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.Linear(256, 128),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(0.5)\n",
    "        )\n",
    "        self.fc = torch.nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.mlp(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# 初始化模型\n",
    "model = ModifiedResNet18()\n",
    "\n",
    "# 加载保存的模型权重\n",
    "model_path = 'best_model.pth'  # 替换为你的模型文件路径\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfcf95b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#对比学习模型\n",
    "import torch.nn as nn\n",
    "\n",
    "class ContrastiveModel(nn.Module):\n",
    "    def __init__(self, input_dim=5194, hidden_dim=256, proj_dim=128):\n",
    "        super().__init__()\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, proj_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return F.normalize(self.projector(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e9c1cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#特征提取器\n",
    "def extract_features(image, transform):\n",
    "    # 应用数据增强\n",
    "    img_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # 前向传播获取激活\n",
    "    with torch.no_grad():\n",
    "        model(img_tensor)\n",
    "    \n",
    "    # 处理各层激活\n",
    "    features = []\n",
    "    for name in hook.activations:\n",
    "        layer_act = hook.activations[name].squeeze()\n",
    "        if len(layer_act.shape) == 3:  # 卷积层特征\n",
    "            features.append(torch.mean(layer_act, dim=(1, 2)))  # 全局平均池化\n",
    "        else:  # 全连接层特征\n",
    "            features.append(layer_act.flatten())\n",
    "    return torch.cat(features).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eaa0425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#钩子函数\n",
    "class ActivationHook:\n",
    "    def __init__(self):\n",
    "        self.activations = {}\n",
    "        \n",
    "    def get_hook(self, name):\n",
    "        def hook(module, input, output):\n",
    "            self.activations[name] = output.detach()\n",
    "        return hook\n",
    "\n",
    "# 初始化钩子管理器\n",
    "hook = ActivationHook()\n",
    "\n",
    "# 为模型的所有卷积层和全连接层注册钩子\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, (torch.nn.Conv2d, torch.nn.Linear)):\n",
    "        module.register_forward_hook(hook.get_hook(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee687827",
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据增强手段\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 定义多种数据增强方法\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da2af508",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [03:27<00:00, 20.74s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [03:29<00:00, 20.96s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "# 修改后的build_dataset函数，生成视图对\n",
    "def build_paired_dataset(data_dict, label_type, num_samples=1000):\n",
    "    pairs = []\n",
    "    \n",
    "    for class_name in tqdm(data_dict.keys()):\n",
    "        df = data_dict[class_name]\n",
    "        for idx in range(min(num_samples, len(df))):\n",
    "            img = df.iloc[idx]['image']\n",
    "            \n",
    "            # 生成两个不同的增强视图\n",
    "            view1 = extract_features(img, train_transform)\n",
    "            view2 = extract_features(img, train_transform)\n",
    "            \n",
    "            pairs.append((view1, view2, label_type))\n",
    "    \n",
    "    return pairs\n",
    "    \n",
    "# 构建配对数据集\n",
    "normal_pairs = build_paired_dataset(dataframes, 0)\n",
    "adv_pairs = build_paired_dataset(pgds, 1)\n",
    "all_pairs = normal_pairs + adv_pairs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 划分训练集、验证集、测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_pairs, temp_pairs = train_test_split(all_pairs, test_size=0.4, random_state=42)\n",
    "val_pairs, test_pairs = train_test_split(temp_pairs, test_size=0.5, random_state=42)\n",
    "\n",
    "# 创建Dataset类\n",
    "class ContrastivePairDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, pairs):\n",
    "        self.pairs = pairs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        view1, view2, label = self.pairs[idx]\n",
    "        return (\n",
    "            torch.FloatTensor(view1),\n",
    "            torch.FloatTensor(view2),\n",
    "            torch.LongTensor([label])\n",
    "        )\n",
    "\n",
    "# 创建DataLoader\n",
    "train_dataset = ContrastivePairDataset(train_pairs)\n",
    "val_dataset = ContrastivePairDataset(val_pairs)\n",
    "test_dataset = ContrastivePairDataset(test_pairs)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a61442ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NTXentLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        z: 归一化后的特征向量，形状为(2N, D)\n",
    "        前N个是第一个增强视图，后N个是第二个增强视图\n",
    "        \"\"\"\n",
    "        N = z.size(0) // 2\n",
    "        \n",
    "        # 计算相似度矩阵\n",
    "        sim_matrix = torch.matmul(z, z.T) / self.temperature\n",
    "        \n",
    "        # 创建正样本mask\n",
    "        pos_mask = torch.zeros_like(sim_matrix, dtype=torch.bool)\n",
    "        for i in range(N):\n",
    "            pos_mask[i, i+N] = True\n",
    "            pos_mask[i+N, i] = True\n",
    "        \n",
    "        # 排除自对比\n",
    "        self_mask = torch.eye(2*N, dtype=torch.bool, device=z.device)\n",
    "        pos_mask = pos_mask & ~self_mask\n",
    "        \n",
    "        # 构造logits和标签\n",
    "        pos_logits = sim_matrix[pos_mask].view(2*N, -1)\n",
    "        neg_logits = sim_matrix[~pos_mask & ~self_mask].view(2*N, -1)\n",
    "        \n",
    "        logits = torch.cat([pos_logits, neg_logits], dim=1)\n",
    "        labels = torch.zeros(2*N, dtype=torch.long, device=z.device)\n",
    "        \n",
    "        return self.criterion(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "572cc5d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Loss: 2.0043, Train Accuracy: 0.5416\n",
      "Val Loss: 1.1224, Val Accuracy: 0.7845\n",
      "Saved best model!\n",
      "Epoch 2\n",
      "Train Loss: 0.8501, Train Accuracy: 0.8387\n",
      "Val Loss: 0.7176, Val Accuracy: 0.8662\n",
      "Saved best model!\n",
      "Epoch 3\n",
      "Train Loss: 0.6199, Train Accuracy: 0.9010\n",
      "Val Loss: 0.5558, Val Accuracy: 0.9074\n",
      "Saved best model!\n",
      "Epoch 4\n",
      "Train Loss: 0.5165, Train Accuracy: 0.9236\n",
      "Val Loss: 0.4829, Val Accuracy: 0.9221\n",
      "Saved best model!\n",
      "Epoch 5\n",
      "Train Loss: 0.4432, Train Accuracy: 0.9412\n",
      "Val Loss: 0.4670, Val Accuracy: 0.9267\n",
      "Saved best model!\n",
      "Epoch 6\n",
      "Train Loss: 0.4012, Train Accuracy: 0.9470\n",
      "Val Loss: 0.4127, Val Accuracy: 0.9354\n",
      "Saved best model!\n",
      "Epoch 7\n",
      "Train Loss: 0.3669, Train Accuracy: 0.9561\n",
      "Val Loss: 0.4032, Val Accuracy: 0.9415\n",
      "Saved best model!\n",
      "Epoch 8\n",
      "Train Loss: 0.3358, Train Accuracy: 0.9604\n",
      "Val Loss: 0.3816, Val Accuracy: 0.9426\n",
      "Saved best model!\n",
      "Epoch 9\n",
      "Train Loss: 0.3001, Train Accuracy: 0.9666\n",
      "Val Loss: 0.3878, Val Accuracy: 0.9483\n",
      "Epoch 10\n",
      "Train Loss: 0.2851, Train Accuracy: 0.9712\n",
      "Val Loss: 0.3374, Val Accuracy: 0.9497\n",
      "Saved best model!\n",
      "Epoch 11\n",
      "Train Loss: 0.2561, Train Accuracy: 0.9768\n",
      "Val Loss: 0.3195, Val Accuracy: 0.9554\n",
      "Saved best model!\n",
      "Epoch 12\n",
      "Train Loss: 0.2464, Train Accuracy: 0.9798\n",
      "Val Loss: 0.3167, Val Accuracy: 0.9555\n",
      "Saved best model!\n",
      "Epoch 13\n",
      "Train Loss: 0.2358, Train Accuracy: 0.9810\n",
      "Val Loss: 0.2991, Val Accuracy: 0.9591\n",
      "Saved best model!\n",
      "Epoch 14\n",
      "Train Loss: 0.2237, Train Accuracy: 0.9817\n",
      "Val Loss: 0.2966, Val Accuracy: 0.9561\n",
      "Saved best model!\n",
      "Epoch 15\n",
      "Train Loss: 0.2102, Train Accuracy: 0.9836\n",
      "Val Loss: 0.2917, Val Accuracy: 0.9571\n",
      "Saved best model!\n",
      "Epoch 16\n",
      "Train Loss: 0.2012, Train Accuracy: 0.9842\n",
      "Val Loss: 0.2759, Val Accuracy: 0.9599\n",
      "Saved best model!\n",
      "Epoch 17\n",
      "Train Loss: 0.1884, Train Accuracy: 0.9871\n",
      "Val Loss: 0.2823, Val Accuracy: 0.9635\n",
      "Epoch 18\n",
      "Train Loss: 0.1851, Train Accuracy: 0.9862\n",
      "Val Loss: 0.2686, Val Accuracy: 0.9619\n",
      "Saved best model!\n",
      "Epoch 19\n",
      "Train Loss: 0.1731, Train Accuracy: 0.9888\n",
      "Val Loss: 0.2627, Val Accuracy: 0.9654\n",
      "Saved best model!\n",
      "Epoch 20\n",
      "Train Loss: 0.1778, Train Accuracy: 0.9874\n",
      "Val Loss: 0.2754, Val Accuracy: 0.9673\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "# 初始化模型和损失\n",
    "model_contrast = ContrastiveModel().to(device)\n",
    "optimizer = torch.optim.Adam(model_contrast.parameters(), lr=2e-3)\n",
    "ntxent_loss = NTXentLoss(temperature=0.07)\n",
    "\n",
    "def validate(model, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for view1, view2, _ in dataloader:\n",
    "            view1 = view1.to(device)\n",
    "            view2 = view2.to(device)\n",
    "            \n",
    "            z1 = model(view1)\n",
    "            z2 = model(view2)\n",
    "            z = torch.cat([z1, z2], dim=0)\n",
    "            \n",
    "            # 计算损失\n",
    "            loss = ntxent_loss(z)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # 计算准确率\n",
    "            N = z.size(0) // 2\n",
    "            sim_matrix = torch.matmul(z, z.T) / ntxent_loss.temperature\n",
    "            \n",
    "            # 创建正样本mask\n",
    "            pos_mask = torch.zeros_like(sim_matrix, dtype=torch.bool)\n",
    "            for i in range(N):\n",
    "                pos_mask[i, i+N] = True\n",
    "                pos_mask[i+N, i] = True\n",
    "            \n",
    "            # 排除自对比\n",
    "            self_mask = torch.eye(2*N, dtype=torch.bool, device=z.device)\n",
    "            pos_mask = pos_mask & ~self_mask\n",
    "            \n",
    "            # 构造logits和标签\n",
    "            pos_logits = sim_matrix[pos_mask].view(2*N, -1)\n",
    "            neg_logits = sim_matrix[~pos_mask & ~self_mask].view(2*N, -1)\n",
    "            \n",
    "            logits = torch.cat([pos_logits, neg_logits], dim=1)\n",
    "            labels = torch.zeros(2*N, dtype=torch.long, device=z.device)\n",
    "            \n",
    "            # 计算准确率\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct = (preds == labels).sum().item()\n",
    "            total_correct += correct\n",
    "            total_samples += labels.size(0)\n",
    "    \n",
    "    accuracy = total_correct / total_samples if total_samples > 0 else 0\n",
    "    return total_loss / len(dataloader), accuracy\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(30):\n",
    "    # 训练阶段\n",
    "    model_contrast.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_samples = 0\n",
    "    \n",
    "    for view1, view2, _ in train_loader:\n",
    "        view1 = view1.to(device)\n",
    "        view2 = view2.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 前向传播\n",
    "        z1 = model_contrast(view1)\n",
    "        z2 = model_contrast(view2)\n",
    "        z = torch.cat([z1, z2], dim=0)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = ntxent_loss(z)\n",
    "        \n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # 计算准确率\n",
    "        N = z.size(0) // 2\n",
    "        sim_matrix = torch.matmul(z, z.T) / ntxent_loss.temperature\n",
    "        \n",
    "        # 创建正样本mask\n",
    "        pos_mask = torch.zeros_like(sim_matrix, dtype=torch.bool)\n",
    "        for i in range(N):\n",
    "            pos_mask[i, i+N] = True\n",
    "            pos_mask[i+N, i] = True\n",
    "        \n",
    "        # 排除自对比\n",
    "        self_mask = torch.eye(2*N, dtype=torch.bool, device=z.device)\n",
    "        pos_mask = pos_mask & ~self_mask\n",
    "        \n",
    "        # 构造logits和标签\n",
    "        pos_logits = sim_matrix[pos_mask].view(2*N, -1)\n",
    "        neg_logits = sim_matrix[~pos_mask & ~self_mask].view(2*N, -1)\n",
    "        \n",
    "        logits = torch.cat([pos_logits, neg_logits], dim=1)\n",
    "        labels = torch.zeros(2*N, dtype=torch.long, device=z.device)\n",
    "        \n",
    "        # 计算准确率\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct = (preds == labels).sum().item()\n",
    "        train_correct += correct\n",
    "        train_samples += labels.size(0)\n",
    "    \n",
    "    # 验证阶段\n",
    "    val_loss, val_accuracy = validate(model_contrast, val_loader)\n",
    "    \n",
    "    # 计算训练准确率\n",
    "    train_accuracy = train_correct / train_samples if train_samples > 0 else 0\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    print(f\"Train Loss: {train_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model_contrast.state_dict(), \"best_ntxent_model.pth\")\n",
    "        print(\"Saved best model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085d418f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3066a5d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
